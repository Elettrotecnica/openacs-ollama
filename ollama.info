<?xml version="1.0"?>
<!-- Generated by the OpenACS Package Manager -->

<package key="ollama" url="http://openacs.org/repository/apm/packages/ollama" type="apm_application">
    <package-name>Ollama</package-name>
    <pretty-plural>Ollama</pretty-plural>
    <initial-install-p>f</initial-install-p>
    <singleton-p>f</singleton-p>
    <implements-subsite-p>f</implements-subsite-p>
    <inherit-templates-p>f</inherit-templates-p>

    <version name="1.1.0" url="http://openacs.org/repository/download/apm/ollama-1.1.0.apm">
        <owner url="mailto:antonio@elettrotecnica.it">Antonio Pisano</owner>
        <summary>Ollama LLM Tool integration</summary>
        <release-date>2024-12-18</release-date>
        <vendor url="https://www.elettrotecnica.it">L&#39;Elettrotecnica S.r.l.</vendor>
        <description format="text/html">This package provides an integration to the Ollama LLM tool (https://github.com/ollama/ollama).</description>
        <maturity>0</maturity>

        <provides url="ollama" version="1.1.0"/>
        <requires url="search" version="6.0.0d1"/>
        <requires url="notifications" version="6.0.0d2"/>

        <callbacks>
            <callback type="after-install"  proc="ollama::install::package_install"/>
            <callback type="before-install"  proc="ollama::install::preinstall_checks"/>
            <callback type="before-uninstall"  proc="ollama::install::before_uninstall"/>
        </callbacks>
        <parameters>
            <parameter scope="global" datatype="string"  min_n_values="1"  max_n_values="1"  name="default_generation_model"  description="Default model for text generation." section_name="General"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="embedding_batch_size"  default="50" description="Number of documents to be sent simultaneously to the Ollama backend to generate embeddings." section_name="Indexing"/>
            <parameter scope="global" datatype="string"  min_n_values="1"  max_n_values="1"  name="embedding_model"  default="all-minilm" description="Model used to generate embeddings. See https://ollama.com/search?c=embedding for possible values." section_name="Indexing"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="indexing_chunk_overlap"  default="100" description="By how many words will chunk overlap when indexing content." section_name="Indexing"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="indexing_chunk_size"  default="1000" description="Number of words for each chunk when splitting the content for indexing." section_name="Indexing"/>
            <parameter scope="global" datatype="string"  min_n_values="1"  max_n_values="1"  name="ollama_host"  default="http://localhost:11434" description="Ollama host instance." section_name="General"/>
            <parameter scope="global" datatype="text"  min_n_values="1"  max_n_values="1"  name="rag_context_template"  default="Use the following context as your learned knowledge, enclosed within &lt;context&gt;&lt;/context&gt; XML tags.
&lt;context&gt;
$context
&lt;/context&gt;
When answering the user:
- If you don&#39;t know the answer, simply state that you don&#39;t know.
- If you&#39;re unsure, seek clarification.
- Avoid mentioning that the information was sourced from the context.
- Respond in accordance with the language of the user&#39;s question.
Given the context information, address the query.
Query: $query" description="Template that will be added to the chat prompt in order to instruct the LLM to use additional context when providing a reply. It can contain the variables &#34;context&#34; (the actual extra content) and &#34;query&#34; (the question to the model), which will be substituted." section_name="RAG"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="rag_top_k"  default="5" description="Max number of entries, sorted by decreasing relevance, to retrieve when fetching context for Retrieval Augmented Generation." section_name="RAG"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="similarity_threshold"  default="0.9" description="Minimal similarity threshold used to decide if a document is relevant. This value expresses a cosine similarity in the 0 (highest) to 2 (smallest) range." section_name="Search"/>
            <parameter scope="global" datatype="number"  min_n_values="1"  max_n_values="1"  name="websearch_p"  default="0" description="Allow to search the web when querying the model?" section_name="RAG"/>
        </parameters>

    </version>
</package>
